---
title: 'A Practical Guide the Hamiltonian Monte Carlo Method'
author: <p>Spencer Miller<span style='font-variant:small-caps'>, fcas, maaa</span> & Kenny Smart<span style='font-variant:small-caps'>, fcas, maaa</span></p>
date: '`r Sys.Date()`'
output: pdf_document
editor_options: 
  markdown: 
    wrap: 100
abstract: 'To be completed later.'
---

**Keywords** — Bayesian, Monte Carlo, Markov Chain, Forecasting, Predictions, Behavioral Economics

# Introduction

Some text

## Target Audience

-   An actuary who has finished exams a few years ago
-   An actuary who constantly finds their estimates to be out of line with results
-   An actuary interested in learning about Stan but finds the math too onerous or intimidating
-   An actuary with limited data

## Current Theories on Prediction

-   Point estimates do not provide for an adequate measure of process / parameter / model risk
-   Simple MCMC models layer in process risk but still fail to account for parameter risk / model
    risk
-   Using a copula for parameters ignores the likelihood of occurring given the data

## Yes, Even Actuaries are Human

When making predictions, people often rely on heuristics. While these are typically useful from an
evolutionary standpoint, they can "... lead to systematic and predictable errors".^[1]^

There are several factors at play when making predictions:

-   *Insensitivity to sample size*: An actuary may predict some future value based on limited data.
-   *Insensitivity to prior probability of outcomes*: Example?
-   *Misconception of chance*: Say something about process risk or that an actuary may infer some
    sort of pattern where one does not exist.
-   *Insensitivity to predictive accuracy*: Taking a risk manager’s assessment of a new claims
    handling process at face value.
-   *The illusion of validity*: Using an exposure base as a proxy for loss?
-   *Misconceptions of Regression*: Letting one bad AY influence the expectation of the next AY.
-   *Anchoring*: Using the prior prediction.

# Basics of Bayesian MCMC

Before we get into the Hamiltonian Monte Carlo method, we provide a brief overview of Bayesian MCMC.

-   A **Markov process** is a random process for which the future depends only on the present state.
    For example, the outcome of rolling a die does not depend on the previous roll.

-   **Monte Carlo** methods use random sampling to approximate an outcome. Continuing the die roll
    example, you could replicate the outcome of a single roll $r$ by generating a random value $u$
    from\
    the distribution *U* \~ Uniform[0,1], where $r=$$\lceil$$6u$$\rceil$.

-   **Bayesian statistics** is an approach to data analysis based on Bayes’ theorem, where available
    knowledge about parameters in a statistical model is updated with the information in observed
    data. In our example, let's assume that the die is not fair (unbeknownst to us) with a
    distribution equal to $Prob(r = i) = i/21$ and that we have observed the following rolls: $y$ =
    {3, 4, 5, 6, 4, 3, 5, 4, 2}.

    Using a Bayesian approach, we have three components:

    <!--# https://www.r-bloggers.com/2020/01/applied-bayesian-statistics-using-stan-and-r/ -->

    -   *Likelihood function*: This is the parametric form of our data, $p(y|\theta)$, given a set
        of parameters, $\theta$.

    -   *Prior distribution*: This is our belief of the distribution of our parameters prior to
        seeing the data, $p(\theta)$. In this case, we might assume that the die is fair:
        $p(\theta) = 1/6$.

    -   *Posterior distribution*: The result of updating our prior belief about the parameters given
        the data, $p(\theta|y) \propto p(\theta) * p(y|\theta)$.

This process can be done using **Stan**, an open-source software, via common coding languages (e.g.,
python and R). In this paper, we leverage the RStan package, though there are numerous other
packages that can be used.

-   Need to discuss the key parameters (thin, chains, etc.).
-   Discuss sampling method: Gibbs vs Metropolis Hastings vs Hamiltonian Monte Carlo

Applying this process to our loaded die example: *Kenny to complete*

# An Example in Action

For a simple example, we’ll use the procedure to estimate the annual number of worldwide earthquakes
greater than 6.0 magnitude. The data includes 14,014 earthquakes occurring since 1900 Let's assume
it's 2011 and we are tasked with estimating the number of 6.0 magnitude earthquakes in 2012.

First, let's get the data we'll be using in our example:

```{r get_data}
data("eqlist", package = 'CASdatasets')

data.table::setDT(x = eqlist)

dplyr::glimpse(eqlist)
```

Next, we'll get the count data by year between 1983 and 2011.

```{r count_data, echo=FALSE, fig.height=4, fig.width=6, fig.align='center'}
true_count <- eqlist[lubridate::year(day) == 2012, .N]

count_data <- eqlist[
  lubridate::year(day) %in% 1983:2011, 
  .(count = .N), 
  keyby = .(year = lubridate::year(day))
]

ggplot2::ggplot(
  data = count_data,
  mapping = ggplot2::aes(x = year, y = count)
) +
  ggplot2::geom_point() +
  ggplot2::scale_x_continuous(name = 'Year', breaks = seq(1985, 2010, 5)) +
  ggplot2::scale_y_continuous(name = '') +
  ggplot2::theme_classic() +
  ggplot2::ggtitle(label = 'Number of Worldwide 6.0 Magniture Earthquakes by Year')
```

At first glance, you might make the following observations about the data:

-   Since around 1997, there appears to be an upward trend.
-   Something else.
-   Something else.

```{r method_A, include=FALSE}
method_A <- mean(count_data$count)
count_cv <- sd(count_data$count) / method_A # 14.07%
selected_cv <- 0.15
```

In the simplest case, an actuary may decide that a straight average of historical counts is the best
approximation of future counts. In this case, the average number per year is `r round(method_A, 0)`
("Method A").

```{r method_B, include=FALSE}
method_B <- mean(count_data[year %in% 2007:2011, count])
```

However, you might decide that given the recent upward trend, an all-year average might be low.
Instead, you opt to use a five-year average of `r round(method_B, 0)` ("Method B").

Your next logical step might be to add some process risk around your estimate by fitting a
distribution to the data. Using the maximum-likelihood-estimates of a few common distributions, you
settle on using a Lognormal distribution parameterized using a mean of `r round(method_B, 0)` and
coefficient of variation of `r selected_cv * 100`% (based on all year coefficient of variation).

```{r method_C, echo=FALSE, fig.height=4, fig.width=6, fig.align='center', warning=FALSE}
ggplot2::ggplot(
  data = count_data,
  mapping = ggplot2::aes(sample = count)
) +
  ggplot2::geom_abline(
    mapping = ggplot2::aes(intercept = 0, slope = 1),
    color = 'black'
  ) +
  ggplot2::stat_qq(
    mapping = ggplot2::aes(color = 'Lognormal'),
    geom = 'path',
    linetype = 'dotted',
    linewidth = 1,
    distribution = stats::qlnorm,
    dparams = as.list(MASS::fitdistr(x = count_data$count, densfun = "lognormal")$estimate)
  ) +
  ggplot2::stat_qq(
    mapping = ggplot2::aes(color = 'Normal'),
    geom = 'path',
    linetype = 'dotted',
    linewidth = 1,
    distribution = stats::qnorm,
    dparams = as.list(MASS::fitdistr(x = count_data$count, densfun = "normal")$estimate)
  ) +
  ggplot2::stat_qq(
    mapping = ggplot2::aes(color = 'Weibull'),
    geom = 'path',
    linetype = 'dotted',
    size = 1,
    distribution = stats::qweibull,
    dparams = as.list(MASS::fitdistr(x = count_data$count, densfun = "weibull")$estimate)
  ) +
  ggplot2::stat_qq(
    mapping = ggplot2::aes(color = 'Poisson'),
    geom = 'path',
    linetype = 'dotted',
    linewidth = 1,
    distribution = stats::qpois,
    dparams = as.list(MASS::fitdistr(x = count_data$count, densfun = "poisson")$estimate)
  ) +
  ggplot2::stat_qq(
    mapping = ggplot2::aes(color = 'Neg. Binomial'),
    geom = 'path',
    linetype = 'dotted',
    linewidth = 1,
    distribution = stats::qnbinom,
    dparams = as.list(MASS::fitdistr(x = count_data$count, densfun = "negative binomial")$estimate)
  ) +
  ggplot2::theme_classic() +
  ggplot2::theme(legend.position = 'bottom') +
  ggplot2::scale_color_manual(
    name = 'Distribution',
    values = c(
      'Lognormal' = 'red',
      'Normal' = 'orange',
      'Weibull' = 'green',
      'Poisson' = 'blue',
      'Neg. Binomial' = 'purple'
    )
  ) + 
  ggplot2::ggtitle(label = 'Quantile-Quantile Plot')

method_C_sigma <- sqrt(log(1 + selected_cv ^ 2))
method_C_mu <- log(method_B) - 0.5 * method_C_sigma ^ 2

set.seed(314159)
method_C_sample <- stats::rlnorm(
  n = 10000, 
  meanlog = method_C_mu,
  sdlog = method_C_sigma
)

method_C <- mean(method_C_sample)

percentile_C <- sum(method_C_sample < true_count) / 10000
```

After running 10,000 simulations with your selected distribution, you're left with a central
estimate of `r round(method_C, 0)` ("Method C"). But as we discussed earlier, there are a few
problems with just relying on our data:

-   The sample size is on the low end (n = `r nrow(count_data)`).
-   Regression to the mean.
-   It might look like there is a "new normal" but you could be seeing a trend where there isn't
    one.

So how do we handle these possible biases? That's where Bayesian MCMC comes in. Our first model will
assume a wide prior. We'll start with our distribution from Method C:

-   *mu* \~ Normal(`r round(method_C_mu, 3)`, `r round(method_C_mu * 0.05, 3)`)
-   *sigma* \~ Exponential(`r round(method_C_sigma, 3)`)

```{r method_D, include=FALSE}
method_D_stan_code <- '
  data{
    int<lower = 0> N;
    real<lower = 0> obs[N];
    real mu_mean;
    real mu_cv;
    real<lower = 0> sigma_mean;
  }
  
  parameters {
    real mu;
    real<lower = 0> sigma;
  }

  model {
    mu ~ normal(mu_mean, mu_mean * mu_cv);
    sigma ~ exponential(sigma_mean);
  
    for(i in 1:N) {
      obs[i] ~ lognormal(mu, sigma);
    }
  }
'

method_D_stan_model <- rstan::stan(
  model_code = method_D_stan_code,
  data = list(
    N = nrow(count_data), 
    obs = count_data$count,
    mu_mean = method_C_mu,
    mu_cv = 0.05, # 5% coef. of variation
    sigma_mean = method_C_sigma
  ),
  chains = 4,
  iter = 5000,
  warmup = 2500,
  seed = 314159
)

method_D_params <- list(
  'meanlog' = rstan::extract(object = method_D_stan_model, pars = 'mu')[[1]],
  'sdlog' = rstan::extract(object = method_D_stan_model, pars = 'sigma')[[1]]
)

set.seed(314159)
method_D_sample <- stats::rlnorm(
  n = 10000, 
  meanlog = method_D_params[['meanlog']],
  sdlog = method_D_params[['sdlog']]
)

method_D <- mean(method_D_sample)

percentile_D <- sum(method_D_sample < true_count) / 10000
```

After running 10,000 simulations with your selected distribution, you're left with a central
estimate of `r round(method_D, 0)` ("Method D"). Since you used a wide prior, your result will be
fairly close to Method A even though you had a much higher prior. That is because the data is
overwhelmingly lower, thus a higher estimate is less likely.

Next, let's test "tighter" our prior. After all, we're pretty confident of the recent trend. We'll
assume that our Lognormal distribution has the following revised prior distributions:

-   *mu* \~ Normal(`r round(method_C_mu, 3)`, `r round(method_C_mu * 0.01, 3)`)
-   *sigma* \~ Exponential(`r round(1 / method_C_sigma, 3)`)

Let's compare each result to the true number of fires that occurred in 2012 (`r true_count`).

```{r compare, echo=FALSE, fig.height=4, fig.width=6, fig.align='center'}
ggplot2::ggplot() +
  ggplot2::geom_line(
    mapping = ggplot2::aes(
      y = c(0.6, 1.4),
      x = c(method_A, method_A)
    )
  ) +
  ggplot2::geom_line(
    mapping = ggplot2::aes(
      y = c(1.6, 2.4),
      x = c(method_B, method_B)
    )
  ) +
  ggplot2::geom_boxplot(
    mapping = ggplot2::aes(
      y = 3,
      x = sort(method_C_sample)
    ),
    outliers = FALSE
  ) +
  ggplot2::geom_boxplot(
    mapping = ggplot2::aes(
      y = 4,
      x = sort(method_D_sample)
    ),
    outliers = FALSE
  ) +
  ggplot2::geom_jitter(
    mapping = ggplot2::aes(x = count_data$count, y = 0),
    height = 0.25
  ) +
  ggplot2::geom_vline(
    xintercept = true_count,
    color = 'blue'
  ) +
  ggplot2::theme_classic() +
  ggplot2::scale_x_continuous(name = '') +
  ggplot2::scale_y_continuous(
    name = '',
    breaks = 0:4,
    labels = c('Empirical', paste('Method', LETTERS[1:4]))
  ) + 
  ggplot2::ggtitle(label = 'Comparison of Methods')
```

It appears that all four methods severely overestimated the true counts. However, if we look at
Method C versus Method D, the true count is approximately equal to the
`r round(percentile_C, 3) * 100`% confidence level of Method C but the
`r round(percentile_D, 3) * 100`% confidence level of Method D.

With the benefit of hindsight, let's see why we overestimated the true counts in all four methods.
As it turns out, we fell prey to (at least) two key biases:

-   Humans just aren't that great at identifying random processes. For example, a series of coin
    tosses with all heads is seen as "less random" than a series with alternative heads and tails
    even though both results are equally likely.
-   Regression to the mean. As seen in the chart, the high average for 2008-2011 was followed by a
    low average in 2012-2023. This resulted in the new all-year average (1983-2023) being nearly
    identical to the all-year average prior to the rise (1983-2007).

```{r plot_full, echo=FALSE, fig.height=4, fig.width=6, fig.align='center'}
count_data_full <- eqlist[
  lubridate::year(day) %in% 1983:2023, 
  .(count = .N), 
  keyby = .(year = lubridate::year(day))
]

ggplot2::ggplot() +
  ggplot2::geom_point(
    data = count_data_full,
    mapping = ggplot2::aes(x = year, y = count)
  ) +
  ggplot2::geom_vline(
    xintercept = 2012, 
    color = 'blue'
  ) +
  ggplot2::geom_line(
    mapping = ggplot2::aes(
      x = c(1982.5, 2007.5),
      y = rep(mean(count_data_full[year %in% 1983:2007, count]), 2)
    ),
    linetype = 'dashed'
  ) +
  ggplot2::geom_line(
    mapping = ggplot2::aes(
      x = c(2007.5, 2011.5),
      y = rep(mean(count_data_full[year %in% 2008:2011, count]), 2)
    ),
    linetype = 'dashed'
  ) +
  ggplot2::geom_line(
    mapping = ggplot2::aes(
      x = c(2011.5, 2023.5),
      y = rep(mean(count_data_full[year %in% 2012:2023, count]), 2)
    ),
    linetype = 'dashed'
  ) +
  ggplot2::geom_line(
    mapping = ggplot2::aes(
      x = c(1982.5, 2023.5),
      y = rep(mean(count_data_full[year %in% 1983:2023, count]), 2)
    ),
    linetype = 'dotted'
  ) +
  ggplot2::scale_x_continuous(name = 'Year', breaks = seq(1985, 2020, 5)) +
  ggplot2::scale_y_continuous(name = '') +
  ggplot2::theme_classic() +
  ggplot2::ggtitle(label = 'Number of Worldwide 6.0 Magniture Earthquakes by Year')
```

# Supplemental Information

## Literature Review

While our paper focused on the usage of Bayesian MCMC methods for forecasting purposes, the methods
can and have been used in other applications. We provide a non-exhaustive list below of papers that
utilize these methods to some extent:

-   Reserving^2^

-   Renewal Functions^3^

-   Risk Margins^4^

-   Trends^5^

We also believe there are several other possible applications, ranging from the selection of
development factors to estimating reserve variability. We leave it to the reader to explore these.

## Acknowledgements

We would like to extend our gratitude to our colleagues for their thoughtful reviews (Rajesh
Sahasrabuddhe, Molly Colleary, Alex Taggart, and Chris Schneider).

## Biographies of the Authors

Spencer is a Senior Manager with Oliver Wyman Actuarial Consulting, Inc., located in Philadelphia.
He holds a Bachelor of Science from Lebanon Valley College.

Kenny is a Senior Manager with Oliver Wyman Actuarial Consulting, Inc, located in Chicago. He holds
a Bachelor of Science degree in Actuarial Mathematics and Statistics from the University of
Pittsburgh.

## Citations

[1] A. Tversky, and D. Kahneman, Judgment under uncertainty: Heuristics and biases, Science 185,
1124–1131 (1974).

[2] Meyers, G. 2015. “Stochastic Loss Reserving Using Bayesian MCMC Models.” CAS Monograph #1.

[3] Aminzadeh, M.S., and Min Deng. 2022. “Bayesian Estimation of Renewal Function Based on
Pareto-Distributed Inter-Arrival Times via an MCMC Algorithm.” Variance 15 (2).

[4] Meyers, G. 2019. “A Cost-of-Capital Risk Margin Formula for Nonlife Insurance Liabilities.”
Variance 12 (2).

[5] Schmid, F. 2013. "Bayesian Trend Selection." Casualty Actuarial Society E-Forum, Spring 2013.

## R Packages

Barrett, Tyson, Matt Dowle, Arun Srinivasan, Jan Gorecki, Michael Chirico, Toby Hocking, Benjamin
Schwendinger, and Ivan Krylov. 2025. “Data.table: Extension of ‘Data.frame‘.”
<https://CRAN.Rproject.org/package=data.table>.

Dutang, Christophe, and Arthur Charpentier. 2025. “CASdatasets: Insurance Datasets.”
<https://doi.org/10.57745/P0KHAG>.

Stan Development Team. 2025. “{RStan}: The {r} Interface to {Stan}.” <https://mc-stan.org/>.

Wickham, Hadley. 2016. “Ggplot2: Elegant Graphics for Data Analysis.”
<https://ggplot2.tidyverse.org>.
